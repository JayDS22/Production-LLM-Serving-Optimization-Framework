# Model Configuration
MODEL_NAME=meta-llama/Llama-2-7b-hf
TENSOR_PARALLEL_SIZE=4
QUANTIZATION_MODE=int8
MAX_BATCH_SIZE=256
GPU_MEMORY_UTILIZATION=0.9

# Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1

# Optimization Settings
ENABLE_FLASH_ATTENTION=true
ENABLE_KV_CACHE=true
KV_CACHE_DTYPE=auto
MAX_CONTEXT_LENGTH=4096
BATCH_TIMEOUT_MS=50
MAX_WAITING_TOKENS=20

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090
ENABLE_TRACING=false

# Hugging Face
HF_TOKEN=your_huggingface_token_here
HF_HOME=/root/.cache/huggingface

# API Security (optional)
API_KEY=your_api_key_here

# Redis Configuration (optional)
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/server.log
